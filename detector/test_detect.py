import cv2
import numpy as np
import tensorflow as tf
import time
import threading
from collections import deque
import os
from datetime import datetime

class CupDetectorCamera:
    def __init__(self, model_path, camera_id=0, confidence_threshold=0.5):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∫—Ä—É–∂–µ–∫ –¥–ª—è –∫–∞–º–µ—Ä—ã
        
        Args:
            model_path: –ø—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            camera_id: ID –∫–∞–º–µ—Ä—ã (–æ–±—ã—á–Ω–æ 0 –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π)
            confidence_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        """
        self.model_path = model_path
        self.camera_id = camera_id
        self.confidence_threshold = confidence_threshold
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        try:
            self.model = tf.keras.models.load_model(model_path)
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É
        print(f"üîÑ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ {camera_id}...")
        self.cap = cv2.VideoCapture(camera_id)
        
        if not self.cap.isOpened():
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ {camera_id}")
            raise RuntimeError(f"–ö–∞–º–µ—Ä–∞ {camera_id} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞–º–µ—Ä—ã
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {self.frame_width}x{self.frame_height}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.fps_counter = deque(maxlen=30)
        self.detection_times = deque(maxlen=30)
        
        # –§–ª–∞–≥–∏
        self.running = False
        self.save_detections = False
        self.detection_count = 0
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π
        self.save_dir = "cup_detections"
        os.makedirs(self.save_dir, exist_ok=True)
        
    def preprocess_frame(self, frame, target_size=(224, 224)):
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR -> RGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            h, w = rgb_frame.shape[:2]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
            scale = min(target_size[0] / h, target_size[1] / w)
            new_h = int(h * scale)
            new_w = int(w * scale)
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            resized = cv2.resize(rgb_frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å padding
            final_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)
            
            # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            y_offset = (target_size[0] - new_h) // 2
            x_offset = (target_size[1] - new_w) // 2
            final_image[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è ImageNet
            normalized = final_image.astype("float32") / 255.0
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            normalized = (normalized - mean) / std
            
            return normalized, scale, x_offset, y_offset
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return None
    
    def detect_cups_in_frame(self, frame):
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –∫—Ä—É–∂–µ–∫ –≤ –∫–∞–¥—Ä–µ
        """
        start_time = time.time()
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä
        result = self.preprocess_frame(frame)
        if result is None:
            return None, 0
        
        processed_frame, scale, x_offset, y_offset = result
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–æ–¥–µ–ª—å
        try:
            predictions = self.model.predict(
                np.expand_dims(processed_frame, axis=0), 
                verbose=0
            )
            
            classification_confidence = predictions[0][0][0]
            bbox_coords = predictions[1][0]
            
            detection_time = time.time() - start_time
            self.detection_times.append(detection_time)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            detection_result = {
                'has_cup': classification_confidence > self.confidence_threshold,
                'confidence': float(classification_confidence),
                'bbox': {
                    'center_x': float(bbox_coords[0]),
                    'center_y': float(bbox_coords[1]),
                    'width': float(bbox_coords[2]),
                    'height': float(bbox_coords[3])
                },
                'preprocessing_params': {
                    'scale': scale,
                    'x_offset': x_offset,
                    'y_offset': y_offset
                }
            }
            
            return detection_result, detection_time
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
            return None, 0
    
    def draw_detection_on_frame(self, frame, detection_result):
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞ –∫–∞–¥—Ä–µ
        """
        if detection_result is None:
            return frame
        
        frame_copy = frame.copy()
        h, w = frame_copy.shape[:2]
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ —É–≥–ª—É —ç–∫—Ä–∞–Ω–∞
        confidence = detection_result['confidence']
        status_text = f"Cup: {'YES' if detection_result['has_cup'] else 'NO'}"
        confidence_text = f"Conf: {confidence:.3f}"
        
        # –¶–≤–µ—Ç —Å—Ç–∞—Ç—É—Å–∞
        status_color = (0, 255, 0) if detection_result['has_cup'] else (0, 0, 255)
        
        # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        cv2.rectangle(frame_copy, (10, 10), (300, 80), (0, 0, 0), -1)
        cv2.rectangle(frame_copy, (10, 10), (300, 80), status_color, 2)
        
        # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
        cv2.putText(frame_copy, status_text, (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
        cv2.putText(frame_copy, confidence_text, (20, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # –†–∏—Å—É–µ–º bbox –µ—Å–ª–∏ –∫—Ä—É–∂–∫–∞ –Ω–∞–π–¥–µ–Ω–∞
        if detection_result['has_cup']:
            bbox = detection_result['bbox']
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª–∏
            center_x = bbox['center_x'] * w
            center_y = bbox['center_y'] * h
            width = bbox['width'] * w
            height = bbox['height'] * h
            
            # Corner coordinates
            x1 = int(center_x - width / 2)
            y1 = int(center_y - height / 2)
            x2 = int(center_x + width / 2)
            y2 = int(center_y + height / 2)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∫–∞–¥—Ä–∞
            x1 = max(0, min(x1, w))
            y1 = max(0, min(y1, h))
            x2 = max(0, min(x2, w))
            y2 = max(0, min(y2, h))
            
            # –†–∏—Å—É–µ–º bbox
            cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), 3)
            
            # –†–∏—Å—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É
            cv2.circle(frame_copy, (int(center_x), int(center_y)), 5, (0, 255, 0), -1)
            
            # –ü–æ–¥–ø–∏—Å—å –∫ bbox
            label = f"Cup {confidence:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            
            # –§–æ–Ω –¥–ª—è –ø–æ–¥–ø–∏—Å–∏
            cv2.rectangle(frame_copy, 
                         (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0] + 10, y1), 
                         (0, 255, 0), -1)
            
            # –¢–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏
            cv2.putText(frame_copy, label, (x1 + 5, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
        
        return frame_copy
    
    def draw_stats_on_frame(self, frame):
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞ –∫–∞–¥—Ä–µ
        """
        h, w = frame.shape[:2]
        
        # FPS
        avg_fps = np.mean(self.fps_counter) if self.fps_counter else 0
        fps_text = f"FPS: {avg_fps:.1f}"
        
        # –í—Ä–µ–º—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        avg_detection_time = np.mean(self.detection_times) if self.detection_times else 0
        detection_text = f"Det: {avg_detection_time*1000:.0f}ms"
        
        # –°—á–µ—Ç—á–∏–∫ –¥–µ—Ç–µ–∫—Ü–∏–π
        count_text = f"Detections: {self.detection_count}"
        
        # –†–∏—Å—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –ø—Ä–∞–≤–æ–º —É–≥–ª—É
        stats_y = h - 100
        cv2.rectangle(frame, (w-200, stats_y-30), (w-10, h-10), (0, 0, 0), -1)
        cv2.rectangle(frame, (w-200, stats_y-30), (w-10, h-10), (255, 255, 255), 1)
        
        cv2.putText(frame, fps_text, (w-190, stats_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, detection_text, (w-190, stats_y+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, count_text, (w-190, stats_y+40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return frame
    
    def draw_instructions(self, frame):
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        """
        h, w = frame.shape[:2]
        
        instructions = [
            "Controls:",
            "ESC/Q - Exit",
            "S - Save detection",
            "SPACE - Toggle auto-save",
            "C - Clear counter"
        ]
        
        # –†–∏—Å—É–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ –ª–µ–≤–æ–º –Ω–∏–∂–Ω–µ–º —É–≥–ª—É
        start_y = h - len(instructions) * 25 - 10
        cv2.rectangle(frame, (10, start_y-10), (200, h-10), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, start_y-10), (200, h-10), (255, 255, 255), 1)
        
        for i, instruction in enumerate(instructions):
            y_pos = start_y + i * 20
            color = (0, 255, 255) if i == 0 else (255, 255, 255)
            cv2.putText(frame, instruction, (15, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # –°—Ç–∞—Ç—É—Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        if self.save_detections:
            cv2.putText(frame, "AUTO-SAVE: ON", (15, start_y + len(instructions) * 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        return frame
    
    def save_detection_image(self, frame, detection_result):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞–¥—Ä —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        
        if detection_result and detection_result['has_cup']:
            conf = detection_result['confidence']
            filename = f"cup_detected_{timestamp}_conf{conf:.3f}.jpg"
        else:
            filename = f"no_cup_{timestamp}.jpg"
        
        filepath = os.path.join(self.save_dir, filename)
        cv2.imwrite(filepath, frame)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
        
        return filepath
    
    def run(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –¥–µ—Ç–µ–∫—Ü–∏–∏
        """
        print("\nüöÄ –ó–ê–ü–£–°–ö REAL-TIME –î–ï–¢–ï–ö–¶–ò–ò –ö–†–£–ñ–ï–ö")
        print("=" * 50)
        print("ESC –∏–ª–∏ Q - –≤—ã—Ö–æ–¥")
        print("S - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–∞–¥—Ä")
        print("SPACE - –≤–∫–ª/–≤—ã–∫–ª –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π")
        print("C - —Å–±—Ä–æ—Å–∏—Ç—å —Å—á–µ—Ç—á–∏–∫")
        print("=" * 50)
        
        self.running = True
        
        try:
            while self.running:
                frame_start_time = time.time()
                
                # –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä
                ret, frame = self.cap.read()
                if not ret:
                    print("‚ùå –û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞ –∫–∞–¥—Ä–∞")
                    break
                
                # –î–µ—Ç–µ–∫—Ü–∏—è
                detection_result, detection_time = self.detect_cups_in_frame(frame)
                
                # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                if detection_result and detection_result['has_cup']:
                    self.detection_count += 1
                
                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                frame_with_detection = self.draw_detection_on_frame(frame, detection_result)
                frame_with_stats = self.draw_stats_on_frame(frame_with_detection)
                final_frame = self.draw_instructions(frame_with_stats)
                
                # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                if (self.save_detections and detection_result and 
                    detection_result['has_cup'] and 
                    detection_result['confidence'] > 0.8):
                    self.save_detection_image(final_frame, detection_result)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–¥—Ä
                cv2.imshow('Cup Detection Camera', final_frame)
                
                # –ü–æ–¥—Å—á–µ—Ç FPS
                frame_time = time.time() - frame_start_time
                self.fps_counter.append(1.0 / frame_time if frame_time > 0 else 0)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
                key = cv2.waitKey(1) & 0xFF
                
                if key == 27 or key == ord('q'):  # ESC –∏–ª–∏ Q
                    break
                elif key == ord('s'):  # S - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
                    self.save_detection_image(final_frame, detection_result)
                elif key == ord(' '):  # SPACE - –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                    self.save_detections = not self.save_detections
                    status = "ON" if self.save_detections else "OFF"
                    print(f"üîÑ –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {status}")
                elif key == ord('c'):  # C - —Å–±—Ä–æ—Å–∏—Ç—å —Å—á–µ—Ç—á–∏–∫
                    self.detection_count = 0
                    print("üîÑ –°—á–µ—Ç—á–∏–∫ —Å–±—Ä–æ—à–µ–Ω")
                
        except KeyboardInterrupt:
            print("\n‚õî –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """
        –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
        """
        print("\nüßπ –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤...")
        self.running = False
        
        if hasattr(self, 'cap') and self.cap.isOpened():
            self.cap.release()
        
        cv2.destroyAllWindows()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ï–°–°–ò–ò:")
        print(f"   –í—Å–µ–≥–æ –¥–µ—Ç–µ–∫—Ü–∏–π –∫—Ä—É–∂–µ–∫: {self.detection_count}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π FPS: {np.mean(self.fps_counter):.1f}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {np.mean(self.detection_times)*1000:.0f}ms")
        print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ: {self.save_dir}")
        print("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ!")

# ===== –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ =====

def test_camera_connection(camera_id=0):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ
    """
    print(f"üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–º–µ—Ä—ã {camera_id}...")
    
    cap = cv2.VideoCapture(camera_id)
    
    if not cap.isOpened():
        print(f"‚ùå –ö–∞–º–µ—Ä–∞ {camera_id} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return False
    
    ret, frame = cap.read()
    if not ret:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã {camera_id}")
        cap.release()
        return False
    
    h, w = frame.shape[:2]
    print(f"‚úÖ –ö–∞–º–µ—Ä–∞ {camera_id} —Ä–∞–±–æ—Ç–∞–µ—Ç: {w}x{h}")
    
    cap.release()
    return True

def list_available_cameras(max_cameras=5):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞–º–µ—Ä—ã
    """
    print("üîç –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä...")
    available_cameras = []
    
    for i in range(max_cameras):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret:
                h, w = frame.shape[:2]
                available_cameras.append((i, w, h))
                print(f"‚úÖ –ö–∞–º–µ—Ä–∞ {i}: {w}x{h}")
        cap.release()
    
    if not available_cameras:
        print("‚ùå –ö–∞–º–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    return available_cameras

def run_cup_detection_camera(model_path="cup_detection_model_final.h5", 
                           camera_id=0, 
                           confidence_threshold=0.5):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –∫—Ä—É–∂–µ–∫ —á–µ—Ä–µ–∑ –∫–∞–º–µ—Ä—É
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
        if not os.path.exists(model_path):
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            return
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É
        if not test_camera_connection(camera_id):
            print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π camera_id –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã")
            return
        
        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
        detector = CupDetectorCamera(
            model_path=model_path,
            camera_id=camera_id,
            confidence_threshold=confidence_threshold
        )
        
        detector.run()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
        import traceback
        traceback.print_exc()

# ===== MAIN =====

if __name__ == "__main__":
    print("üéØ REAL-TIME –î–ï–¢–ï–ö–¶–ò–Ø –ö–†–£–ñ–ï–ö –ß–ï–†–ï–ó USB –ö–ê–ú–ï–†–£")
    print("=" * 60)
    
    # –ü–æ–∏—Å–∫ –∫–∞–º–µ—Ä
    cameras = list_available_cameras()
    
    if not cameras:
        print("‚ùå –ö–∞–º–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ USB –∫–∞–º–µ—Ä—ã.")
        exit(1)
    
    # –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞ –∫–∞–º–µ—Ä–µ 0...")
    run_cup_detection_camera(
        model_path="cup_detection_model_final.h5",
        camera_id=0,
        confidence_threshold=0.3
    )