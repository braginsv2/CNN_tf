import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import time
import threading
import queue
from collections import deque
import argparse
import os

class RealTimeCupDetector:
    def __init__(self, model_path='advanced_cup_classifier.h5', target_size=(224, 224)):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∫—Ä—É–∂–µ–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        """
        self.target_size = target_size
        self.model = None
        self.cap = None
        
        # –ë—É—Ñ–µ—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.prediction_buffer = deque(maxlen=10)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.fps_counter = deque(maxlen=30)
        self.frame_count = 0
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.confidence_threshold = 0.7
        self.show_preprocessing = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.load_model(model_path)
        
        print("üé• –î–ï–¢–ï–ö–¢–û–† –ö–†–£–ñ–ï–ö –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò")
        print("="*50)
        print("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:")
        print("  'q' - –≤—ã—Ö–æ–¥")
        print("  'p' - –ø–æ–∫–∞–∑–∞—Ç—å/—Å–∫—Ä—ã—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É")
        print("  's' - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–¥—Ä")
        print("  '+'/'-' - –∏–∑–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
        print("  'r' - —Å–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
        print("="*50)
    
    def load_model(self, model_path):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        try:
            print(f"ü§ñ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_path}")
            self.model = load_model(model_path)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {self.model.count_params():,}")
            
            # –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º –º–æ–¥–µ–ª—å
            dummy_input = np.zeros((1, *self.target_size, 3), dtype=np.float32)
            self.model.predict(dummy_input, verbose=0)
            print("üî• –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥—Ä–µ—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.model = None
    
    def preprocess_frame(self, frame):
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ (—Ç–∞ –∂–µ, —á—Ç–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR -> RGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            h, w = rgb_frame.shape[:2]
            
            if h > w:
                new_h = self.target_size[0]
                new_w = int(w * self.target_size[0] / h)
            else:
                new_w = self.target_size[1]
                new_h = int(h * self.target_size[1] / w)
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            resized = cv2.resize(rgb_frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å padding
            final_image = np.zeros((self.target_size[0], self.target_size[1], 3), dtype=np.uint8)
            
            # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            y_offset = (self.target_size[0] - new_h) // 2
            x_offset = (self.target_size[1] - new_w) // 2
            final_image[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
            
            # ImageNet –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            normalized = final_image.astype("float32") / 255.0
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            normalized = (normalized - mean) / std
            
            return normalized, final_image
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return None, None
    
    def predict_cup(self, frame):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –∫—Ä—É–∂–∫–∏ –≤ –∫–∞–¥—Ä–µ
        """
        if self.model is None:
            return None, 0.0
        
        processed_frame, display_frame = self.preprocess_frame(frame)
        if processed_frame is None:
            return None, 0.0
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        start_time = time.time()
        prediction = self.model.predict(np.expand_dims(processed_frame, axis=0), verbose=0)
        inference_time = time.time() - start_time
        
        predicted_class = prediction.argmax()
        confidence = prediction.max()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.prediction_buffer.append((predicted_class, confidence))
        
        # –°–≥–ª–∞–∂–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if len(self.prediction_buffer) >= 3:
            recent_predictions = list(self.prediction_buffer)[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∫–∞–¥—Ä–æ–≤
            avg_confidence = np.mean([conf for _, conf in recent_predictions])
            most_common_class = max(set([cls for cls, _ in recent_predictions]), 
                                  key=[cls for cls, _ in recent_predictions].count)
            
            class_name = "Cup" if most_common_class == 1 else "No Cup"
            return class_name, avg_confidence, inference_time, display_frame
        else:
            class_name = "Cup" if predicted_class == 1 else "No Cup"
            return class_name, confidence, inference_time, display_frame
    
    def draw_results(self, frame, prediction, confidence, fps, inference_time):
        """
        –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –∫–∞–¥—Ä–µ
        """
        height, width = frame.shape[:2]
        
        # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
        if prediction == "Cup":
            if confidence > self.confidence_threshold:
                color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π - —É–≤–µ—Ä–µ–Ω–Ω–æ –∫—Ä—É–∂–∫–∞
                status = "CUP DETECTED"
            else:
                color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π - –≤–æ–∑–º–æ–∂–Ω–æ –∫—Ä—É–∂–∫–∞
                status = "CUP (LOW CONF)"
        else:
            if confidence > self.confidence_threshold:
                color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π - —É–≤–µ—Ä–µ–Ω–Ω–æ –Ω–µ –∫—Ä—É–∂–∫–∞
                status = "NO CUP"
            else:
                color = (128, 128, 128)  # –°–µ—Ä—ã–π - –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å
                status = "UNCERTAIN"
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        font = cv2.FONT_HERSHEY_SIMPLEX
        
        # –°—Ç–∞—Ç—É—Å (–±–æ–ª—å—à–∏–º–∏ –±—É–∫–≤–∞–º–∏)
        cv2.putText(frame, status, (20, 50), font, 1.5, color, 3)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        info_lines = [
            f"Confidence: {confidence:.3f}",
            f"FPS: {fps:.1f}",
            f"Inference: {inference_time*1000:.1f}ms",
            f"Threshold: {self.confidence_threshold:.2f}"
        ]
        
        for i, line in enumerate(info_lines):
            y_pos = 100 + i * 30
            cv2.putText(frame, line, (20, y_pos), font, 0.7, (255, 255, 255), 2)
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ–ª–æ—Å–∞)
        bar_width = 300
        bar_height = 20
        bar_x = width - bar_width - 20
        bar_y = 30
        
        # –§–æ–Ω –ø–æ–ª–æ—Å—ã
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), 
                     (50, 50, 50), -1)
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–æ—Å—ã
        fill_width = int(bar_width * confidence)
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + fill_width, bar_y + bar_height), 
                     color, -1)
        
        # –†–∞–º–∫–∞ –ø–æ–ª–æ—Å—ã
        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), 
                     (255, 255, 255), 2)
        
        # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ª–∏–Ω–∏—è)
        threshold_x = bar_x + int(bar_width * self.confidence_threshold)
        cv2.line(frame, (threshold_x, bar_y), (threshold_x, bar_y + bar_height), 
                (255, 255, 0), 2)
        
        # –ë–æ–ª—å—à–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤ —Ü–µ–Ω—Ç—Ä–µ –¥–ª—è —è—Ä–∫–∏—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π
        if prediction == "Cup" and confidence > self.confidence_threshold:
            center_x, center_y = width // 2, height // 2
            cv2.circle(frame, (center_x, center_y), 100, (0, 255, 0), 5)
            cv2.putText(frame, "‚òï", (center_x - 30, center_y + 15), 
                       font, 2, (0, 255, 0), 3)
        
        return frame
    
    def run_webcam_detection(self, camera_id=0):
        """
        –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –≤–µ–±-–∫–∞–º–µ—Ä—É
        """
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            return
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        self.cap = cv2.VideoCapture(camera_id)
        if not self.cap.isOpened():
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É {camera_id}")
            return
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞–º–µ—Ä—ã
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        print(f"‚úÖ –ö–∞–º–µ—Ä–∞ {camera_id} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        print("üé¨ –ù–∞—á–∏–Ω–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é...")
        
        saved_frames = 0
        
        while True:
            start_time = time.time()
            
            # –ß–∏—Ç–∞–µ–º –∫–∞–¥—Ä
            ret, frame = self.cap.read()
            if not ret:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–¥—Ä")
                break
            
            self.frame_count += 1
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            result = self.predict_cup(frame)
            if result is None:
                continue
            
            if len(result) == 4:
                prediction, confidence, inference_time, preprocessed_display = result
            else:
                prediction, confidence, inference_time = result
                preprocessed_display = None
            
            # –í—ã—á–∏—Å–ª—è–µ–º FPS
            frame_time = time.time() - start_time
            self.fps_counter.append(1.0 / frame_time if frame_time > 0 else 0)
            current_fps = np.mean(self.fps_counter)
            
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            display_frame = self.draw_results(frame, prediction, confidence, 
                                            current_fps, inference_time)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –æ–∫–Ω–æ
            cv2.imshow('Cup Detector - Main', display_frame)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            if self.show_preprocessing and preprocessed_display is not None:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                display_prep = cv2.cvtColor(preprocessed_display, cv2.COLOR_RGB2BGR)
                display_prep = cv2.resize(display_prep, (300, 300))
                cv2.imshow('Cup Detector - Preprocessing', display_prep)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("üëã –í—ã—Ö–æ–¥...")
                break
            elif key == ord('p'):
                self.show_preprocessing = not self.show_preprocessing
                if not self.show_preprocessing:
                    cv2.destroyWindow('Cup Detector - Preprocessing')
                print(f"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: {'–≤–∫–ª—é—á–µ–Ω–∞' if self.show_preprocessing else '–≤—ã–∫–ª—é—á–µ–Ω–∞'}")
            elif key == ord('s'):
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
                filename = f"cup_detection_frame_{saved_frames:04d}.jpg"
                cv2.imwrite(filename, display_frame)
                saved_frames += 1
                print(f"üíæ –ö–∞–¥—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
            elif key == ord('+') or key == ord('='):
                self.confidence_threshold = min(0.99, self.confidence_threshold + 0.05)
                print(f"–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {self.confidence_threshold:.2f}")
            elif key == ord('-'):
                self.confidence_threshold = max(0.01, self.confidence_threshold - 0.05)
                print(f"–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {self.confidence_threshold:.2f}")
            elif key == ord('r'):
                self.prediction_buffer.clear()
                self.fps_counter.clear()
                self.frame_count = 0
                print("üîÑ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–±—Ä–æ—à–µ–Ω–∞")
        
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        self.cap.release()
        cv2.destroyAllWindows()
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏:")
        print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {self.frame_count}")
        print(f"  –°—Ä–µ–¥–Ω–∏–π FPS: {np.mean(self.fps_counter):.1f}")
        print(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {saved_frames}")
    
    def run_video_file_detection(self, video_path, output_path=None):
        """
        –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–µ
        """
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            return
        
        if not os.path.exists(video_path):
            print(f"‚ùå –í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {video_path}")
            return
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª: {video_path}")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"üìπ –í–∏–¥–µ–æ—Ñ–∞–π–ª: {video_path}")
        print(f"  –ö–∞–¥—Ä–æ–≤: {total_frames}")
        print(f"  FPS: {fps}")
        print(f"  –†–∞–∑–º–µ—Ä: {width}x{height}")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—ã–≤–æ–¥ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        writer = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_path}")
        
        frame_num = 0
        cup_detections = 0
        
        print("üé¨ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ...")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_num += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if frame_num % 30 == 0:
                progress = frame_num / total_frames * 100
                print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({frame_num}/{total_frames})")
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            result = self.predict_cup(frame)
            if result is None:
                continue
            
            prediction, confidence, inference_time = result[:3]
            
            # –°—á–∏—Ç–∞–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
            if prediction == "Cup" and confidence > self.confidence_threshold:
                cup_detections += 1
            
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            current_fps = fps  # –î–ª—è –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π FPS
            display_frame = self.draw_results(frame, prediction, confidence, 
                                            current_fps, inference_time)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–¥—Ä
            cv2.imshow('Cup Detector - Video', display_frame)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            if writer:
                writer.write(display_frame)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∞–≤–∏—à–∏
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
        
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        cap.release()
        if writer:
            writer.release()
        cv2.destroyAllWindows()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        detection_rate = cup_detections / frame_num * 100 if frame_num > 0 else 0
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_num}/{total_frames}")
        print(f"  –ö–∞–¥—Ä–æ–≤ —Å –∫—Ä—É–∂–∫–∞–º–∏: {cup_detections}")
        print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π: {detection_rate:.1f}%")
        if output_path and writer:
            print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    """
    parser = argparse.ArgumentParser(description='–î–µ—Ç–µ–∫—Ç–æ—Ä –∫—Ä—É–∂–µ–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏')
    parser.add_argument('--model', '-m', default='advanced_cup_classifier.h5', 
                       help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--camera', '-c', type=int, default=0, 
                       help='ID –∫–∞–º–µ—Ä—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)')
    parser.add_argument('--video', '-v', type=str, 
                       help='–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É (–≤–º–µ—Å—Ç–æ –∫–∞–º–µ—Ä—ã)')
    parser.add_argument('--output', '-o', type=str, 
                       help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∏–¥–µ–æ)')
    parser.add_argument('--threshold', '-t', type=float, default=0.7, 
                       help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.7)')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
    detector = RealTimeCupDetector(args.model)
    detector.confidence_threshold = args.threshold
    
    if detector.model is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.")
        return
    
    try:
        if args.video:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞
            detector.run_video_file_detection(args.video, args.output)
        else:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∫–∞–º–µ—Ä—ã
            detector.run_webcam_detection(args.camera)
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    # –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –∏ –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if len(os.sys.argv) == 1:
        # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—É—Å–∫ —Å –∫–∞–º–µ—Ä–æ–π
        detector = RealTimeCupDetector()
        if detector.model is not None:
            try:
                detector.run_webcam_detection()
            except KeyboardInterrupt:
                print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        else:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª 'advanced_cup_classifier.h5' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
    else:
        main()